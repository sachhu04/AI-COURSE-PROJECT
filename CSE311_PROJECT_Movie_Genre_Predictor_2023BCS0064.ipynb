{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-lpttyopWLO"
      },
      "source": [
        "# **Movie Genre Predictor using ANN**\n",
        "\n",
        "**Name:** **Sachin Singh**  \n",
        "**Roll Number:** **2023BCS0064**  \n",
        "**Course:** **CSE 311 Artificial Intelligence**  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwayRGkpqY3U"
      },
      "source": [
        "###  **Installing Required Dependencies**\n",
        "\n",
        "This step installs all the essential libraries needed for the project:\n",
        "\n",
        "- **kaggle** → for downloading the dataset directly from Kaggle  \n",
        "- **scikit-learn** → preprocessing, metrics, and utilities  \n",
        "- **tensorflow** → building and training the ANN model  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YA6USGrpS5Nj"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle scikit-learn tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6wTMccQqrAe"
      },
      "source": [
        "###  **Importing Required Libraries**\n",
        "\n",
        "In this step, we load all essential Python libraries needed for building the movie genre prediction model.  \n",
        "Key modules include:\n",
        "\n",
        "- `os` and `ast` — for file handling and parsing JSON-like fields  \n",
        "- `numpy` and `pandas` — for numerical operations and structured data processing  \n",
        "- `MultiLabelBinarizer` and `StandardScaler` from `sklearn` — for label encoding and feature scaling  \n",
        "- `train_test_split` — to divide the dataset into training, validation, and testing sets  \n",
        "- `TfidfVectorizer` — for converting text descriptions into numerical features  \n",
        "- `classification_report`, `f1_score`, `precision_score`, `recall_score` — for evaluating multi-label performance  \n",
        "- `Sequential`, `Dense`, `Dropout`, `BatchNormalization` — core components of our ANN model from `tensorflow.keras`  \n",
        "- `EarlyStopping` and `ReduceLROnPlateau` — callbacks to prevent overfitting and improve training stability  \n",
        "- `google.colab.files` — for uploading files like `kaggle.json` when running on Google Colab  \n",
        "- `warnings` — to suppress unwanted warnings for a cleaner notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZSLXa6pTF3-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import ast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from google.colab import files\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpdOjbdUq9hH"
      },
      "source": [
        "###  **Kaggle Authentication**\n",
        "\n",
        "To enable direct dataset downloads from Kaggle, we authenticate using Kaggle API credentials.  \n",
        "These are set securely using environment variables:\n",
        "\n",
        "- `KAGGLE_USERNAME` — your Kaggle account username  \n",
        "- `KAGGLE_KEY` — your Kaggle API key (must be kept private)\n",
        "\n",
        " **Note:** Never share your API key publicly or commit it to version control.  \n",
        "Regenerate the key from your Kaggle account if it is ever exposed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BEk-DslTJh-"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"sachinsingh070\"\n",
        "os.environ['KAGGLE_KEY'] = \"your_kaggle_key_here\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UZS_lMNrafA"
      },
      "source": [
        "### **Downloading the Dataset from Kaggle**\n",
        "\n",
        "This step downloads the required movie dataset directly from Kaggle using the API.  \n",
        "The dataset is stored inside the `movies_dataset/` directory and automatically unzipped.  \n",
        "Once downloaded, all necessary CSV files become available for preprocessing, including the metadata, credits, and keywords files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD0saLZITOqA",
        "outputId": "8b372f3c-9bb0-4201-a6eb-02ad018ab6db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading the-movies-dataset.zip to movies_dataset\n",
            " 58% 131M/228M [00:00<00:00, 1.36GB/s]\n",
            "100% 228M/228M [00:00<00:00, 717MB/s] \n"
          ]
        }
      ],
      "source": [
        "dataset = 'rounakbanik/the-movies-dataset'\n",
        "!kaggle datasets download -d {dataset} -p movies_dataset --unzip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T57e0UurmYb"
      },
      "source": [
        "### **Loading the Movie Metadata**\n",
        "\n",
        "In this step, the primary dataset file **`movies_metadata.csv`** is loaded into a pandas DataFrame.  \n",
        "This file contains core information about each movie, including:\n",
        "\n",
        "- basic identifiers (title, ID, release details)\n",
        "- descriptive fields (overview, tagline)\n",
        "- production-related attributes (budget, revenue, runtime)\n",
        "- preliminary genre information in a structured format\n",
        "\n",
        "After loading, the shape of the dataset is printed to confirm that the file was read successfully and to understand the initial size of the data before preprocessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMzhtjDvTSjm",
        "outputId": "c26ee64a-37e7-46d7-f43e-e6cf79ee3c4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (45466, 24)\n"
          ]
        }
      ],
      "source": [
        "movies = pd.read_csv('movies_dataset/movies_metadata.csv', low_memory=False)\n",
        "print(\"Dataset shape:\", movies.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBVslkVYrpWk"
      },
      "source": [
        "### **Loading the Credits Information**\n",
        "\n",
        "The `credits.csv` file is loaded at this stage to obtain additional details about each movie, specifically the **cast** and **crew** information.  \n",
        "These fields are essential because they provide structured lists of actors and production members, which later help in enriching the feature set used for genre prediction.\n",
        "\n",
        "Displaying the first few rows allows for a quick inspection of the data format and confirms that the file has been read correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "B4bRAAZImCLk",
        "outputId": "d7355e82-548b-4385-80bf-f539c7d7e510"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"credits\",\n  \"rows\": 45476,\n  \"fields\": [\n    {\n      \"column\": \"cast\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 43019,\n        \"samples\": [\n          \"[{'cast_id': 2, 'character': 'Lazar Peacock/Sabata', 'credit_id': '52fe4bca9251416c7510e195', 'gender': 2, 'id': 20581, 'name': 'Jack Betts', 'order': 0, 'profile_path': '/f03shMGYcbPG2EyjkIVAR0YA1RA.jpg'}, {'cast_id': 3, 'character': 'Blonde', 'credit_id': '52fe4bca9251416c7510e199', 'gender': 0, 'id': 100683, 'name': 'Franco Borelli', 'order': 1, 'profile_path': None}, {'cast_id': 4, 'character': 'Roger Murdock', 'credit_id': '52fe4bca9251416c7510e19d', 'gender': 2, 'id': 30898, 'name': 'Gordon Mitchell', 'order': 2, 'profile_path': '/szzvsqfFlkHBUJEiZtRquIhxHqn.jpg'}, {'cast_id': 5, 'character': 'Maya', 'credit_id': '52fe4bca9251416c7510e1a1', 'gender': 1, 'id': 30902, 'name': 'Simonetta Vitelli', 'order': 3, 'profile_path': '/jMnRUMgLV3l6lyB26bd8t9b11m5.jpg'}]\",\n          \"[{'cast_id': 2, 'character': 'Charles', 'credit_id': '590cf25dc3a36864c60039ff', 'gender': 2, 'id': 11276, 'name': 'Tim Pigott-Smith', 'order': 1, 'profile_path': '/yC5fQ2HYxzD5JqnXZKMJ6giExrU.jpg'}, {'cast_id': 3, 'character': 'Kate Middleton', 'credit_id': '590cf268c3a36864fc003a3b', 'gender': 1, 'id': 115679, 'name': 'Charlotte Riley', 'order': 2, 'profile_path': '/pkiZKysfb0oXvaBBm6zWQkWSvVu.jpg'}, {'cast_id': 4, 'character': 'William', 'credit_id': '590cf2769251414e85003b16', 'gender': 2, 'id': 31739, 'name': 'Oliver Chris', 'order': 3, 'profile_path': '/xTnUMtP5MREaHD86XfJ5mYibawq.jpg'}, {'cast_id': 5, 'character': 'Prime Minister Tristram Evans', 'credit_id': '590cf284c3a36864c6003a15', 'gender': 2, 'id': 47933, 'name': 'Adam James', 'order': 4, 'profile_path': '/4dSIRIEEnK2tC1OrgjEykUvOeFw.jpg'}, {'cast_id': 7, 'character': 'Harry', 'credit_id': '590cf2bd9251414e8d0038d1', 'gender': 0, 'id': 1409393, 'name': 'Richard Goulding', 'order': 6, 'profile_path': '/3vM6hrfcU4NLBvWoRxyo8nkPsDU.jpg'}, {'cast_id': 8, 'character': 'Coottsey', 'credit_id': '590cf2e5c3a36864ec0036e3', 'gender': 2, 'id': 1428460, 'name': 'Max Bennett', 'order': 7, 'profile_path': '/fthD8U3aGnQioWAiwvFPcdDQJRV.jpg'}, {'cast_id': 9, 'character': 'Jess', 'credit_id': '590ef2e29251414ead01c7d5', 'gender': 0, 'id': 1595457, 'name': 'Tamara Lawrance', 'order': 8, 'profile_path': None}, {'cast_id': 10, 'character': 'Camilla', 'credit_id': '590ef2f79251414eca01c988', 'gender': 1, 'id': 192933, 'name': 'Margot Leicester', 'order': 9, 'profile_path': '/M2PEeYUdkrd4VjI1D0lsHbiG8t.jpg'}, {'cast_id': 11, 'character': 'James Reiss', 'credit_id': '590ef30fc3a36864d401e229', 'gender': 2, 'id': 15740, 'name': 'Tim McMullan', 'order': 10, 'profile_path': '/8se9JhmD9LE6tiibkGiV51M8rdD.jpg'}, {'cast_id': 12, 'character': 'Mrs Stevens', 'credit_id': '590ef326c3a36864fc01d3f7', 'gender': 0, 'id': 62968, 'name': 'Priyanga Burford', 'order': 11, 'profile_path': '/yTxLb30QwUAs5aoErhnYsnGawG5.jpg'}, {'cast_id': 13, 'character': 'Diana', 'credit_id': '590ef334c3a36864fc01d3ff', 'gender': 1, 'id': 1528819, 'name': 'Katie Brayben', 'order': 12, 'profile_path': '/m7oOBu4cfamQ9wixTyWXNaH9sgn.jpg'}, {'cast_id': 14, 'character': 'Archbishop of Canterbury', 'credit_id': '590ef372c3a368650a01c818', 'gender': 2, 'id': 940, 'name': 'John Shrapnel', 'order': 13, 'profile_path': '/nDIK01IoVNx7cfYOrKqGugItqO9.jpg'}, {'cast_id': 15, 'character': 'Spencer', 'credit_id': '590ef37e9251414ead01c82c', 'gender': 0, 'id': 1455682, 'name': 'Parth Thakerar', 'order': 14, 'profile_path': None}]\",\n          \"[{'cast_id': 1, 'character': 'Himself', 'credit_id': '52fe4a9bc3a368484e15d20d', 'gender': 0, 'id': 1078721, 'name': 'Armand Leroi', 'order': 0, 'profile_path': None}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"crew\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 44669,\n        \"samples\": [\n          \"[{'credit_id': '52fe461ac3a36847f80eccfd', 'department': 'Directing', 'gender': 2, 'id': 107463, 'job': 'Director', 'name': 'Del Tenney', 'profile_path': None}, {'credit_id': '52fe461ac3a36847f80ecd13', 'department': 'Writing', 'gender': 0, 'id': 107464, 'job': 'Screenplay', 'name': 'Richard Hilliard', 'profile_path': None}, {'credit_id': '52fe461ac3a36847f80ecd19', 'department': 'Production', 'gender': 2, 'id': 107463, 'job': 'Producer', 'name': 'Del Tenney', 'profile_path': None}]\",\n          \"[{'credit_id': '52fe45439251416c9102c5bd', 'department': 'Directing', 'gender': 2, 'id': 93975, 'job': 'Director', 'name': 'Lewis Allen', 'profile_path': None}, {'credit_id': '52fe45439251416c9102c5c3', 'department': 'Writing', 'gender': 0, 'id': 111580, 'job': 'Novel', 'name': 'Tiffany Thayer', 'profile_path': None}, {'credit_id': '52fe45439251416c9102c5c9', 'department': 'Writing', 'gender': 2, 'id': 10148, 'job': 'Writer', 'name': 'Warren Duff', 'profile_path': None}, {'credit_id': '52fe45439251416c9102c5cf', 'department': 'Production', 'gender': 2, 'id': 50311, 'job': 'Producer', 'name': 'Robert Fellows', 'profile_path': None}, {'credit_id': '52fe45439251416c9102c5d5', 'department': 'Sound', 'gender': 2, 'id': 26026, 'job': 'Original Music Composer', 'name': 'Victor Young', 'profile_path': None}, {'credit_id': '52fe45439251416c9102c5db', 'department': 'Camera', 'gender': 2, 'id': 8620, 'job': 'Director of Photography', 'name': 'John F. Seitz', 'profile_path': '/6hvivkKP5H5NpPcAViAfUMFgqsu.jpg'}, {'credit_id': '52fe45439251416c9102c5e1', 'department': 'Editing', 'gender': 2, 'id': 30013, 'job': 'Editor', 'name': 'LeRoy Stone', 'profile_path': None}]\",\n          \"[{'credit_id': '52fe45319251416c7504eab9', 'department': 'Writing', 'gender': 2, 'id': 14999, 'job': 'Screenplay', 'name': 'George A. Romero', 'profile_path': '/zNP7wdy48eNNJAAmM0pYbSelUAd.jpg'}, {'credit_id': '52fe45319251416c7504ea8b', 'department': 'Directing', 'gender': 2, 'id': 14999, 'job': 'Director', 'name': 'George A. Romero', 'profile_path': '/zNP7wdy48eNNJAAmM0pYbSelUAd.jpg'}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 112443,\n        \"min\": 2,\n        \"max\": 469172,\n        \"num_unique_values\": 45432,\n        \"samples\": [\n          43942,\n          30139,\n          85389\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "credits"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e21b846e-a929-4913-aa80-c863d4033b60\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cast</th>\n",
              "      <th>crew</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[{'cast_id': 14, 'character': 'Woody (voice)',...</td>\n",
              "      <td>[{'credit_id': '52fe4284c3a36847f8024f49', 'de...</td>\n",
              "      <td>862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[{'cast_id': 1, 'character': 'Alan Parrish', '...</td>\n",
              "      <td>[{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...</td>\n",
              "      <td>8844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[{'cast_id': 2, 'character': 'Max Goldman', 'c...</td>\n",
              "      <td>[{'credit_id': '52fe466a9251416c75077a89', 'de...</td>\n",
              "      <td>15602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[{'cast_id': 1, 'character': \"Savannah 'Vannah...</td>\n",
              "      <td>[{'credit_id': '52fe44779251416c91011acb', 'de...</td>\n",
              "      <td>31357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[{'cast_id': 1, 'character': 'George Banks', '...</td>\n",
              "      <td>[{'credit_id': '52fe44959251416c75039ed7', 'de...</td>\n",
              "      <td>11862</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e21b846e-a929-4913-aa80-c863d4033b60')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e21b846e-a929-4913-aa80-c863d4033b60 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e21b846e-a929-4913-aa80-c863d4033b60');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dd9c0bc5-6746-40ca-9dc6-50d6ebb49a4a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd9c0bc5-6746-40ca-9dc6-50d6ebb49a4a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dd9c0bc5-6746-40ca-9dc6-50d6ebb49a4a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                cast  \\\n",
              "0  [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
              "1  [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
              "2  [{'cast_id': 2, 'character': 'Max Goldman', 'c...   \n",
              "3  [{'cast_id': 1, 'character': \"Savannah 'Vannah...   \n",
              "4  [{'cast_id': 1, 'character': 'George Banks', '...   \n",
              "\n",
              "                                                crew     id  \n",
              "0  [{'credit_id': '52fe4284c3a36847f8024f49', 'de...    862  \n",
              "1  [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...   8844  \n",
              "2  [{'credit_id': '52fe466a9251416c75077a89', 'de...  15602  \n",
              "3  [{'credit_id': '52fe44779251416c91011acb', 'de...  31357  \n",
              "4  [{'credit_id': '52fe44959251416c75039ed7', 'de...  11862  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "credits = pd.read_csv('movies_dataset/credits.csv')\n",
        "credits.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACSJlM2Jry8X"
      },
      "source": [
        "### **Preparing and Aligning the Core Dataset Files**\n",
        "\n",
        "At this stage, the three essential components of the Movies Dataset are loaded:  \n",
        "- the main `movies_metadata` file  \n",
        "- the `credits` file containing cast and crew information  \n",
        "- the `keywords` file containing descriptive tags  \n",
        "\n",
        "All three files rely on a common movie identifier, but the `id` field in these files may appear in different formats, including non-numeric entries.  \n",
        "To ensure consistent merging later, the `id` columns are converted into numeric values, with invalid entries coerced into `NaN`.  \n",
        "Rows with missing or invalid IDs are then removed, since they cannot be reliably matched across files.  \n",
        "\n",
        "This step lays the foundation for accurate merging of metadata, credits, and keyword information into a single unified dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnz50ysfl0up"
      },
      "outputs": [],
      "source": [
        "# Load all relevant files\n",
        "movies = pd.read_csv(\"movies_dataset/movies_metadata.csv\", low_memory=False)\n",
        "credits = pd.read_csv(\"movies_dataset/credits.csv\")\n",
        "keywords_df = pd.read_csv(\"movies_dataset/keywords.csv\")\n",
        "\n",
        "# Convert IDs to numeric\n",
        "movies[\"id\"] = pd.to_numeric(movies[\"id\"], errors=\"coerce\")\n",
        "credits[\"id\"] = pd.to_numeric(credits[\"id\"], errors=\"coerce\")\n",
        "keywords_df[\"id\"] = pd.to_numeric(keywords_df[\"id\"], errors=\"coerce\")\n",
        "\n",
        "# Drop bad IDs\n",
        "movies = movies.dropna(subset=[\"id\"])\n",
        "credits = credits.dropna(subset=[\"id\"])\n",
        "keywords_df = keywords_df.dropna(subset=[\"id\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cNNMVcdsMOD"
      },
      "source": [
        "### **Merging Metadata, Credits, and Keywords**\n",
        "\n",
        "With all datasets cleaned and aligned by their numeric `id` fields, the next step combines them into a single unified DataFrame.  \n",
        "First, the movie metadata is merged with the credits file, adding detailed **cast** and **crew** information for each movie.  \n",
        "Next, the keywords file is merged in, contributing additional descriptive tags that can later be used as textual features.\n",
        "\n",
        "Using a left join ensures that every movie from the main metadata file is preserved, even if corresponding credits or keywords are missing.  \n",
        "The result is a consolidated dataset that brings together all relevant information required for feature extraction and model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRlx4sXrshzj"
      },
      "outputs": [],
      "source": [
        "#Merge: metadata + credits\n",
        "movies = movies.merge(credits, on=\"id\", how=\"left\")\n",
        "\n",
        "# Merge: now metadata has cast + crew\n",
        "# Merge: metadata + keywords\n",
        "movies = movies.merge(keywords_df, on=\"id\", how=\"left\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFn3PhnMslru"
      },
      "source": [
        "### **Extracting Structured Information from JSON-Like Fields**\n",
        "\n",
        "Several columns in the merged dataset—such as `genres`, `cast`, and `keywords`—store information in a JSON-like string format.  \n",
        "To make these fields usable for feature engineering, they must be converted into clean Python lists.\n",
        "\n",
        "A helper function is defined to safely parse these entries and extract specific attributes, such as the `name` field from each JSON object.  \n",
        "Using this function:\n",
        "\n",
        "- `genres_list` is created to represent the list of genres assigned to each movie  \n",
        "- `cast_list` extracts the actors associated with the movie, with the list restricted to the top five for consistency  \n",
        "- `keywords_list` captures descriptive tags that may improve the model’s understanding of thematic elements  \n",
        "\n",
        "Finally, movies that do not contain any valid genre information are removed, since they cannot serve as labeled examples during training.  \n",
        "The resulting dataset is now fully structured and ready for the next stage of preprocessing and feature construction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mirOmJQETVdA",
        "outputId": "a72c496c-67e1-499e-b650-23df7229363f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FINAL SHAPE: (44104, 30)\n",
            "COLUMNS: ['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id', 'imdb_id', 'original_language', 'original_title', 'overview', 'popularity', 'poster_path', 'production_companies', 'production_countries', 'release_date', 'revenue', 'runtime', 'spoken_languages', 'status', 'tagline', 'title', 'video', 'vote_average', 'vote_count', 'cast', 'crew', 'keywords', 'genres_list', 'cast_list', 'keywords_list']\n",
            "SAMPLE ROW:\n",
            "                         title                   genres_list  \\\n",
            "0                    Toy Story   [Animation, Comedy, Family]   \n",
            "1                      Jumanji  [Adventure, Fantasy, Family]   \n",
            "2             Grumpier Old Men             [Romance, Comedy]   \n",
            "3            Waiting to Exhale      [Comedy, Drama, Romance]   \n",
            "4  Father of the Bride Part II                      [Comedy]   \n",
            "\n",
            "                                           cast_list  \\\n",
            "0  [Tom Hanks, Tim Allen, Don Rickles, Jim Varney...   \n",
            "1  [Robin Williams, Jonathan Hyde, Kirsten Dunst,...   \n",
            "2  [Walter Matthau, Jack Lemmon, Ann-Margret, Sop...   \n",
            "3  [Whitney Houston, Angela Bassett, Loretta Devi...   \n",
            "4  [Steve Martin, Diane Keaton, Martin Short, Kim...   \n",
            "\n",
            "                                       keywords_list  \n",
            "0  [jealousy, toy, boy, friendship, friends, riva...  \n",
            "1  [board game, disappearance, based on children'...  \n",
            "2  [fishing, best friend, duringcreditsstinger, o...  \n",
            "3  [based on novel, interracial relationship, sin...  \n",
            "4  [baby, midlife crisis, confidence, aging, daug...  \n"
          ]
        }
      ],
      "source": [
        "def parse_json_list(x, key_name='name'):\n",
        "    try:\n",
        "        lst = ast.literal_eval(x)\n",
        "        return [item.get(key_name, '').strip() for item in lst if isinstance(item, dict)]\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "# Parse genres\n",
        "movies['genres_list'] = movies['genres'].fillna('[]').apply(parse_json_list)\n",
        "\n",
        "# Parse cast (use top 5 actors)\n",
        "movies['cast_list'] = movies['cast'].fillna('[]').apply(parse_json_list)\n",
        "movies['cast_list'] = movies['cast_list'].apply(lambda x: x[:5])   # keep top 5 actors\n",
        "\n",
        "# Parse keywords\n",
        "movies['keywords_list'] = movies['keywords'].fillna('[]').apply(parse_json_list)\n",
        "\n",
        "# Keep only movies with valid genres\n",
        "movies = movies[movies['genres_list'].map(len) > 0].reset_index(drop=True)\n",
        "\n",
        "print(\"FINAL SHAPE:\", movies.shape)\n",
        "print(\"COLUMNS:\", movies.columns.tolist())\n",
        "print(\"SAMPLE ROW:\")\n",
        "print(movies[['title','genres_list','cast_list','keywords_list']].head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8oyl8-ptUQn"
      },
      "source": [
        "### **Constructing a Unified Text Feature**\n",
        "\n",
        "To create a rich textual representation for each movie, multiple descriptive fields are combined into a single consolidated feature.  \n",
        "This unified text includes:\n",
        "\n",
        "- the movie's **title**  \n",
        "- the **overview**, which provides a narrative description  \n",
        "- the extracted **keywords**, representing thematic tags  \n",
        "- the top five actors from the **cast**  \n",
        "\n",
        "Each component is cleaned and joined into a continuous text string, ensuring that all available descriptive information is captured.  \n",
        "This combined text feature serves as the primary input for generating embeddings in the later stages of the model pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBqwWkRgTpu6"
      },
      "outputs": [],
      "source": [
        "movies['text_combined'] = (\n",
        "    movies['title'].fillna('') + \" . \" +\n",
        "    movies['overview'].fillna('') + \" . \" +\n",
        "    movies['keywords_list'].apply(lambda l: \" \".join(l)) + \" . \" +\n",
        "    movies['cast_list'].apply(lambda l: \" \".join(l[:5]))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCtvup2KtarS"
      },
      "source": [
        "### **Preparing Target Labels and Auxiliary Numeric Features**\n",
        "\n",
        "To train a multi-label classifier, the list of genres associated with each movie must be converted into a machine-readable format.  \n",
        "This is accomplished using `MultiLabelBinarizer`, which transforms each movie’s genre list into a binary vector, where each position corresponds to a specific genre.  \n",
        "The resulting matrix `Y` becomes the target output for the model, and the total number of genre classes is recorded for constructing the ANN output layer.\n",
        "\n",
        "In addition to textual information, several numeric attributes are incorporated to enrich the feature set.  \n",
        "Fields such as `popularity`, `vote_average`, `vote_count`, and `runtime` provide quantitative signals that may correlate with genre tendencies.  \n",
        "These values are carefully converted to numeric types, missing entries are filled with zeros, and the final set of numeric features is standardized using `StandardScaler` to ensure balanced input magnitudes during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S44dQto5TwnM",
        "outputId": "d7c0a9fc-4ae6-4ca0-be82-3a4bb8091d4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Genres: ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'Foreign', 'History', 'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction', 'TV Movie', 'Thriller', 'War', 'Western']\n"
          ]
        }
      ],
      "source": [
        "mlb = MultiLabelBinarizer()\n",
        "Y = mlb.fit_transform(movies['genres_list'])\n",
        "n_classes = Y.shape[1]\n",
        "print(\"Genres:\", list(mlb.classes_))\n",
        "\n",
        "# 8. Numeric features\n",
        "num_cols = ['popularity', 'vote_average', 'vote_count', 'runtime']\n",
        "for c in num_cols:\n",
        "    if c in movies.columns:\n",
        "        movies[c] = pd.to_numeric(movies[c], errors='coerce').fillna(0.0)\n",
        "    else:\n",
        "        movies[c] = 0.0\n",
        "num_features = StandardScaler().fit_transform(movies[num_cols].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA6HXpfuthom"
      },
      "source": [
        "### **Generating TF-IDF Text Features**\n",
        "\n",
        "To convert the combined text descriptions into a structured numerical form, a TF-IDF (Term Frequency–Inverse Document Frequency) vectorizer is applied.  \n",
        "This method assigns higher weights to terms that are informative yet not overly common across the dataset, making it well-suited for representing movie descriptions.\n",
        "\n",
        "Using a vocabulary capped at 5,000 terms and standard English stop-word removal, the TF-IDF vectorizer transforms the unified text field into a dense numerical matrix.  \n",
        "Each movie is thus represented by a vector capturing the relative importance of key words and phrases within its description.  \n",
        "The resulting TF-IDF matrix forms the primary textual input for the neural network.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOZahsb2TziV",
        "outputId": "8b3cce3b-3158-4b12-c679-6ecc42f4d597"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing TF-IDF features...\n",
            "TF-IDF shape: (44104, 5000)\n"
          ]
        }
      ],
      "source": [
        "print(\"Computing TF-IDF features...\")\n",
        "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "X_text = tfidf.fit_transform(movies['text_combined']).toarray()\n",
        "print(\"TF-IDF shape:\", X_text.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvJiSxsStkQk"
      },
      "source": [
        "### **Combining Textual and Numeric Features**\n",
        "\n",
        "The TF-IDF matrix derived from the combined text fields captures rich semantic information, while the standardized numeric attributes provide complementary quantitative signals.  \n",
        "To construct a complete feature representation for each movie, these two components are horizontally concatenated into a single input matrix.\n",
        "\n",
        "This unified feature set integrates both descriptive text-based information and structured numerical data, enabling the neural network to learn from multiple modalities simultaneously.  \n",
        "The final shape of the input matrix confirms the total dimensionality that will be fed into the ANN model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzxBlHP_T1-_",
        "outputId": "0359325e-7d1f-4723-89ad-8a5c87f28942"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final input shape: (44104, 5004)\n"
          ]
        }
      ],
      "source": [
        "X = np.hstack([X_text, num_features])\n",
        "print(\"Final input shape:\", X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4V3O08CtuPY"
      },
      "source": [
        "### **Splitting the Dataset into Training, Validation, and Test Sets**\n",
        "\n",
        "To evaluate the model reliably and prevent overfitting, the dataset is divided into three distinct subsets:\n",
        "\n",
        "- **Training set:** used to fit the neural network and learn underlying patterns  \n",
        "- **Validation set:** used during training for tuning hyperparameters and monitoring model performance  \n",
        "- **Test set:** held out completely to measure the final generalization ability of the model  \n",
        "\n",
        "An initial split allocates 10% of the data for testing.  \n",
        "The remaining portion is further divided so that the validation set represents approximately 10% of the overall dataset as well.  \n",
        "Printing the shapes of these splits confirms that the data partitions are correctly sized and ready for model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08rn5aOKT5Am",
        "outputId": "2142a5f4-4730-4344-b2ef-b37e9befbc97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes -> train: (35283, 5004) val: (4410, 5004) test: (4411, 5004)\n"
          ]
        }
      ],
      "source": [
        "X_trainval, X_test, Y_trainval, Y_test = train_test_split(X, Y, test_size=0.10, random_state=42)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_trainval, Y_trainval, test_size=0.1111, random_state=42)\n",
        "print(\"Shapes -> train:\", X_train.shape, \"val:\", X_val.shape, \"test:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmNdNzJ5tz8O"
      },
      "source": [
        "### **Addressing Genre Imbalance with Sample Weights**\n",
        "\n",
        "Movie genres in this dataset are highly imbalanced: some genres occur frequently, while others appear only in a small number of films.  \n",
        "Training a model directly on such data may cause it to favor common genres and ignore the rare ones.\n",
        "\n",
        "To counter this, a weighting strategy is applied:\n",
        "\n",
        "- The frequency of each genre in the training set is calculated.\n",
        "- A median-frequency ratio is used to compute **class weights**, giving more importance to underrepresented genres.\n",
        "- These class weights are then converted into **sample weights**, where each movie receives a weight proportional to the rarity of its associated genres.\n",
        "- Finally, the weights are normalized to maintain stable training behavior.\n",
        "\n",
        "This approach ensures the neural network pays sufficient attention to less frequent genres, improving the balance and fairness of the model’s predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJnJCwG0T80-"
      },
      "outputs": [],
      "source": [
        "freq = Y_train.sum(axis=0)/Y_train.shape[0]\n",
        "median_freq = np.median(freq[freq>0])\n",
        "class_weight_arr = np.array([median_freq/f if f>0 else 1.0 for f in freq])\n",
        "sample_weights = 1.0 + (Y_train * class_weight_arr).sum(axis=1)\n",
        "sample_weights /= np.mean(sample_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_EOM1cLt7bY"
      },
      "source": [
        "### **Building the Artificial Neural Network Model**\n",
        "\n",
        "A fully connected Artificial Neural Network (ANN) is constructed to perform multi-label genre prediction.  \n",
        "The architecture is designed to learn from the combined TF-IDF and numeric feature representation created earlier.\n",
        "\n",
        "Key characteristics of the model:\n",
        "\n",
        "- The input layer matches the dimensionality of the final feature set.\n",
        "- Several dense layers with ReLU activation are used to capture non-linear relationships in the data.\n",
        "- `BatchNormalization` layers help stabilize and accelerate training.\n",
        "- `Dropout` layers are included to reduce overfitting by randomly deactivating neurons during training.\n",
        "- The output layer uses a `sigmoid` activation function, enabling the model to produce independent probability scores for each genre (suitable for multi-label classification).\n",
        "\n",
        "The model is compiled with the `adam` optimizer and a `binary_crossentropy` loss function, which is appropriate for predicting multiple independent labels.  \n",
        "A summary of the architecture is displayed to verify the layout and parameter counts before training begins.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "pvo6YWo4UAuD",
        "outputId": "c0b8aa71-e962-403a-e86f-fc2615438df4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,562,560</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,580</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m2,562,560\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │         \u001b[38;5;34m2,580\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,732,436</span> (10.42 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,732,436\u001b[0m (10.42 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,730,900</span> (10.42 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,730,900\u001b[0m (10.42 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "input_dim = X_train.shape[1]\n",
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()\n",
        "model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(input_dim,)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.35),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.25),\n",
        "    Dense(n_classes, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oedIB4CeuI_W"
      },
      "source": [
        "### **Training the Neural Network with Early Stopping and Learning Rate Scheduling**\n",
        "\n",
        "The model is trained using the prepared training data, with additional mechanisms to improve stability and prevent overfitting:\n",
        "\n",
        "- **EarlyStopping** monitors the validation loss and halts training if no improvement is observed for several epochs.  \n",
        "  This avoids unnecessary training and helps preserve the best-performing model.\n",
        "\n",
        "- **ReduceLROnPlateau** dynamically lowers the learning rate when the validation loss stops improving.  \n",
        "  This allows the optimizer to take smaller, more precise steps during the later stages of training.\n",
        "\n",
        "During training, the model uses:\n",
        "- a batch size of 256,\n",
        "- up to 40 epochs,\n",
        "- the previously computed `sample_weights` to correct for class imbalance.\n",
        "\n",
        "Validation performance is evaluated at each epoch, and the training history is stored for later analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_uH9X_vUC0t",
        "outputId": "f04dd919-64e3-4488-ebf4-d8bf1cc2c9e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "138/138 - 16s - 115ms/step - accuracy: 0.2516 - loss: 0.3962 - val_accuracy: 0.3002 - val_loss: 0.2905 - learning_rate: 1.0000e-03\n",
            "Epoch 2/40\n",
            "138/138 - 11s - 83ms/step - accuracy: 0.4284 - loss: 0.2623 - val_accuracy: 0.3145 - val_loss: 0.2522 - learning_rate: 1.0000e-03\n",
            "Epoch 3/40\n",
            "138/138 - 21s - 153ms/step - accuracy: 0.4870 - loss: 0.2240 - val_accuracy: 0.4154 - val_loss: 0.2204 - learning_rate: 1.0000e-03\n",
            "Epoch 4/40\n",
            "138/138 - 23s - 165ms/step - accuracy: 0.5102 - loss: 0.1998 - val_accuracy: 0.4873 - val_loss: 0.1959 - learning_rate: 1.0000e-03\n",
            "Epoch 5/40\n",
            "138/138 - 12s - 89ms/step - accuracy: 0.5275 - loss: 0.1800 - val_accuracy: 0.5050 - val_loss: 0.1917 - learning_rate: 1.0000e-03\n",
            "Epoch 6/40\n",
            "138/138 - 13s - 91ms/step - accuracy: 0.5356 - loss: 0.1634 - val_accuracy: 0.4930 - val_loss: 0.1975 - learning_rate: 1.0000e-03\n",
            "Epoch 7/40\n",
            "138/138 - 20s - 146ms/step - accuracy: 0.5504 - loss: 0.1487 - val_accuracy: 0.4955 - val_loss: 0.2059 - learning_rate: 1.0000e-03\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "138/138 - 12s - 89ms/step - accuracy: 0.5591 - loss: 0.1368 - val_accuracy: 0.4941 - val_loss: 0.2122 - learning_rate: 1.0000e-03\n",
            "Epoch 9/40\n",
            "138/138 - 20s - 147ms/step - accuracy: 0.5739 - loss: 0.1210 - val_accuracy: 0.5000 - val_loss: 0.2209 - learning_rate: 5.0000e-04\n",
            "Epoch 10/40\n",
            "138/138 - 20s - 148ms/step - accuracy: 0.5807 - loss: 0.1103 - val_accuracy: 0.4941 - val_loss: 0.2289 - learning_rate: 5.0000e-04\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "138/138 - 12s - 88ms/step - accuracy: 0.5912 - loss: 0.1031 - val_accuracy: 0.4961 - val_loss: 0.2357 - learning_rate: 5.0000e-04\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    validation_data=(X_val, Y_val),\n",
        "    epochs=40,\n",
        "    batch_size=256,\n",
        "    sample_weight=sample_weights,\n",
        "    callbacks=callbacks,\n",
        "    verbose=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV0ZQprOudOJ"
      },
      "source": [
        "### **Optimizing Decision Thresholds for Multi-Label Classification**\n",
        "\n",
        "Since the model outputs a probability for each genre independently, a fixed threshold of 0.5 may not yield the best multi-label performance.  \n",
        "Different genres have different frequency distributions, and some require lower or higher thresholds to achieve optimal detection.\n",
        "\n",
        "To address this, a threshold-tuning procedure is applied:\n",
        "\n",
        "- For each genre, a range of candidate thresholds is evaluated on the validation set.\n",
        "- Each threshold is tested by converting probabilities into binary predictions and computing the corresponding F1-score.\n",
        "- The threshold that produces the highest F1-score for that genre is selected.\n",
        "- The resulting vector of genre-specific thresholds is then applied to the model's predictions on the test set.\n",
        "\n",
        "This approach ensures that the final predictions are better calibrated and more sensitive to the characteristics of each genre, significantly improving multi-label performance compared to using a uniform threshold.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0x26BFtU7QC",
        "outputId": "36b3a3be-05cd-482b-a463-cd7d308458ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n"
          ]
        }
      ],
      "source": [
        "def find_best_thresholds(Y_true, Y_prob):\n",
        "    thresholds = np.full(Y_true.shape[1], 0.5)\n",
        "    for c in range(Y_true.shape[1]):\n",
        "        best_t, best_f1 = 0.5, -1\n",
        "        ytrue = Y_true[:, c]\n",
        "        if ytrue.sum()==0:\n",
        "            thresholds[c]=0.5\n",
        "            continue\n",
        "        ts = np.arange(0.05,0.95,0.01)\n",
        "        for t in ts:\n",
        "            f1 = f1_score(ytrue, (Y_prob[:,c]>=t).astype(int), zero_division=0)\n",
        "            if f1>best_f1:\n",
        "                best_f1 = f1\n",
        "                best_t = t\n",
        "        thresholds[c] = best_t\n",
        "    return thresholds\n",
        "\n",
        "Y_val_prob = model.predict(X_val)\n",
        "thresholds = find_best_thresholds(Y_val, Y_val_prob)\n",
        "\n",
        "def apply_thresholds(Y_prob, thresholds):\n",
        "    return (Y_prob>=thresholds).astype(int)\n",
        "\n",
        "Y_test_pred = apply_thresholds(model.predict(X_test), thresholds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDWZyD04ujCz"
      },
      "source": [
        "### **Evaluating Multi-Label Classification Performance**\n",
        "\n",
        "Standard accuracy is not an appropriate measure for multi-label problems, where each movie can belong to multiple genres simultaneously.  \n",
        "Instead, performance is assessed using metrics that better capture the nature of multi-label prediction:\n",
        "\n",
        "- **Micro F1-score:** evaluates overall performance by aggregating contributions from all labels, giving more weight to common genres.\n",
        "- **Macro F1-score:** computes the F1-score for each genre independently and then averages them, providing insight into performance on both frequent and rare genres.\n",
        "- **Micro precision and recall:** measure the model’s ability to correctly identify genres across all predictions.\n",
        "\n",
        "A comprehensive **classification report** is also generated, showing precision, recall, and F1-score for each individual genre.  \n",
        "Together, these metrics provide a balanced and detailed evaluation of the model’s predictive ability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m88DjKYU_9n",
        "outputId": "b56d40cc-0a41-4e28-8fa0-d325a66610db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test metrics: {'micro_f1': 0.621989735491512, 'macro_f1': 0.5520358230078146, 'micro_precision': 0.576736524206095, 'micro_recall': 0.6749491271286281}\n",
            "\n",
            "Classification report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "         Action       0.56      0.64      0.60       637\n",
            "      Adventure       0.49      0.48      0.48       337\n",
            "      Animation       0.53      0.69      0.60       191\n",
            "         Comedy       0.63      0.71      0.67      1375\n",
            "          Crime       0.49      0.63      0.55       449\n",
            "    Documentary       0.78      0.76      0.77       375\n",
            "          Drama       0.70      0.84      0.76      2104\n",
            "         Family       0.58      0.55      0.57       282\n",
            "        Fantasy       0.34      0.61      0.44       234\n",
            "        Foreign       0.17      0.34      0.23       167\n",
            "        History       0.32      0.44      0.37       154\n",
            "         Horror       0.72      0.72      0.72       500\n",
            "          Music       0.61      0.51      0.56       167\n",
            "        Mystery       0.36      0.48      0.41       248\n",
            "        Romance       0.50      0.57      0.53       711\n",
            "Science Fiction       0.67      0.59      0.63       298\n",
            "       TV Movie       0.25      0.18      0.21        83\n",
            "       Thriller       0.54      0.69      0.61       781\n",
            "            War       0.53      0.62      0.58       149\n",
            "        Western       0.83      0.72      0.77        95\n",
            "\n",
            "      micro avg       0.58      0.67      0.62      9337\n",
            "      macro avg       0.53      0.59      0.55      9337\n",
            "   weighted avg       0.59      0.67      0.63      9337\n",
            "    samples avg       0.62      0.71      0.62      9337\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def multilabel_metrics(ytrue, ypred):\n",
        "    return {\n",
        "        'micro_f1': f1_score(ytrue, ypred, average='micro', zero_division=0),\n",
        "        'macro_f1': f1_score(ytrue, ypred, average='macro', zero_division=0),\n",
        "        'micro_precision': precision_score(ytrue, ypred, average='micro', zero_division=0),\n",
        "        'micro_recall': recall_score(ytrue, ypred, average='micro', zero_division=0)\n",
        "    }\n",
        "\n",
        "print(\"Test metrics:\", multilabel_metrics(Y_test, Y_test_pred))\n",
        "print(\"\\nClassification report:\\n\", classification_report(Y_test, Y_test_pred, target_names=mlb.classes_, zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOq1jsFeuq_q"
      },
      "source": [
        "## **Predicting Genres for New Movie Descriptions**\n",
        "\n",
        "A custom prediction function is defined to classify the genres of a new, unseen movie based solely on its textual description.  \n",
        "The function performs the following steps:\n",
        "\n",
        "1. **Text vectorization:**  \n",
        "   The input description is transformed using the previously fitted TF-IDF model to ensure consistency with the training features.\n",
        "\n",
        "2. **Feature construction:**  \n",
        "   The text vector is combined with placeholder numeric features (set to zero), matching the dimensional structure of the original training data.\n",
        "\n",
        "3. **Probability prediction:**  \n",
        "   The trained ANN model outputs a probability score for each genre.\n",
        "\n",
        "4. **Threshold-based decision:**  \n",
        "   Each probability is converted into a binary prediction using the genre-specific thresholds optimized earlier.\n",
        "\n",
        "5. **Top-k genre ranking:**  \n",
        "   The highest-scoring genres are returned along with their corresponding probabilities.\n",
        "\n",
        "This function enables practical genre prediction on arbitrary movie summaries and serves as the interface for applying the trained model beyond the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygQXPBPFVE6D"
      },
      "outputs": [],
      "source": [
        "def predict_genres(text, top_k=5):\n",
        "    X_new_text = tfidf.transform([text]).toarray()\n",
        "    X_new = np.hstack([X_new_text, np.zeros((1,len(num_cols)))])  # numeric features as zeros\n",
        "    probs = model.predict(X_new)[0]\n",
        "    preds = (probs>=thresholds).astype(int)\n",
        "    top_idx = probs.argsort()[-top_k:][::-1]\n",
        "    return [(mlb.classes_[i], float(probs[i])) for i in top_idx], preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXG9zDtYu2sn"
      },
      "source": [
        "### **Demonstrating the Model on Example Descriptions**\n",
        "\n",
        "To illustrate how the trained model performs on unseen movie summaries, a series of example descriptions are provided.  \n",
        "For each example, the prediction function outputs:\n",
        "\n",
        "- the top predicted genres along with their probability scores  \n",
        "- the full binary prediction mask indicating which genres were activated  \n",
        "\n",
        "These examples help verify the model’s practical behavior and demonstrate its ability to identify multiple relevant genres from natural language descriptions.  \n",
        "Below, several test descriptions are evaluated to showcase the model’s genre prediction capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y176ofBlVJI_",
        "outputId": "940aa7d8-1745-44de-cdbc-d6c1f7007317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\n",
            "Top predicted genres & probs: [('Comedy', 0.9414530992507935), ('Action', 0.3839086592197418), ('Thriller', 0.20027127861976624), ('Drama', 0.15489935874938965), ('Crime', 0.11070700734853745)]\n",
            "Binary mask for all genres: [1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "example = \"A ragtag team of mercenaries attempt a heist, but personal conflicts spiral into chaos and dark comedy.\"\n",
        "topk, mask = predict_genres(example, top_k=5)\n",
        "print(\"\\nTop predicted genres & probs:\", topk)\n",
        "print(\"Binary mask for all genres:\", mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szZJdg3JWCPz",
        "outputId": "60d71f87-b72f-402f-9151-17f51d059a29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\n",
            "Top predicted genres & probs: [('Science Fiction', 0.9885070323944092), ('Action', 0.6739530563354492), ('Thriller', 0.4483526647090912), ('Horror', 0.37217339873313904), ('Adventure', 0.13695670664310455)]\n",
            "Binary mask for all genres: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]\n"
          ]
        }
      ],
      "source": [
        "example = \"A team of astronauts is sent on a dangerous mission to explore a distant planet, but they encounter hostile alien lifeforms that threaten their survival.\"\n",
        "topk, mask = predict_genres(example, top_k=5)\n",
        "print(\"\\nTop predicted genres & probs:\", topk)\n",
        "print(\"Binary mask for all genres:\", mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpRZ9LefWIHR",
        "outputId": "33636733-d6c0-42b3-c27e-f0bfcd81f901"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\n",
            "Top predicted genres & probs: [('Comedy', 0.9777870774269104), ('Romance', 0.7659969925880432), ('Family', 0.1861397922039032), ('Music', 0.18331356346607208), ('Drama', 0.1773184835910797)]\n",
            "Binary mask for all genres: [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "example = \"Two rival chefs in a small town are forced to compete in a cooking contest, but unexpected romance blooms amidst the chaos.\"\n",
        "topk, mask = predict_genres(example, top_k=5)\n",
        "print(\"\\nTop predicted genres & probs:\", topk)\n",
        "print(\"Binary mask for all genres:\", mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2VqTc1PWYzh",
        "outputId": "e2a3d969-deaf-4863-9625-15676b27e40d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\n",
            "Top predicted genres & probs: [('Crime', 0.8949007987976074), ('Thriller', 0.874430775642395), ('Mystery', 0.6925297975540161), ('Drama', 0.38880160450935364), ('Action', 0.3847935199737549)]\n",
            "Binary mask for all genres: [1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n"
          ]
        }
      ],
      "source": [
        "example = \"A detective races against time to stop a serial killer who leaves cryptic clues at each crime scene.\"\n",
        "topk, mask = predict_genres(example, top_k=5)\n",
        "print(\"\\nTop predicted genres & probs:\", topk)\n",
        "print(\"Binary mask for all genres:\", mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPoLKwX5Wf4y",
        "outputId": "82b6b4a8-cf0e-4708-a321-6dab1c3d4378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\n",
            "Top predicted genres & probs: [('War', 0.9778497815132141), ('Drama', 0.8548486232757568), ('Action', 0.4780610203742981), ('Thriller', 0.17443959414958954), ('History', 0.09370403736829758)]\n",
            "Binary mask for all genres: [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0]\n"
          ]
        }
      ],
      "source": [
        "example = \"During World War II, a young soldier struggles with the horrors of battle and the moral dilemmas of loyalty and survival.\"\n",
        "topk, mask = predict_genres(example, top_k=5)\n",
        "print(\"\\nTop predicted genres & probs:\", topk)\n",
        "print(\"Binary mask for all genres:\", mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxnjB9S4WkUe",
        "outputId": "4b3fad18-f21f-45a4-e341-e12346d92555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\n",
            "Top predicted genres & probs: [('Horror', 0.9759166240692139), ('Thriller', 0.2501448094844818), ('Comedy', 0.19881510734558105), ('Mystery', 0.16861572861671448), ('Fantasy', 0.13059157133102417)]\n",
            "Binary mask for all genres: [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "example = \"A family moves into a remote old mansion, only to discover it is haunted by vengeful spirits from the past.\"\n",
        "topk, mask = predict_genres(example, top_k=5)\n",
        "print(\"\\nTop predicted genres & probs:\", topk)\n",
        "print(\"Binary mask for all genres:\", mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACoFAMlDWoNn",
        "outputId": "a1c53e8b-bbc7-4be2-8191-901517f76e14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\n",
            "Top predicted genres & probs: [('Family', 0.8784245252609253), ('Adventure', 0.7780735492706299), ('Animation', 0.7720664739608765), ('Fantasy', 0.745086669921875), ('Drama', 0.13261695206165314)]\n",
            "Binary mask for all genres: [0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "example = \"A young dragon befriends a boy and together they embark on a magical journey to save their kingdom from dark forces.\"\n",
        "topk, mask = predict_genres(example, top_k=5)\n",
        "print(\"\\nTop predicted genres & probs:\", topk)\n",
        "print(\"Binary mask for all genres:\", mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyJaMyiPWsg4",
        "outputId": "c4bd38f1-cb86-466b-aac6-b48a51a4bf2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\n",
            "Top predicted genres & probs: [('Comedy', 0.9134494662284851), ('Action', 0.869952917098999), ('Crime', 0.6738135814666748), ('Thriller', 0.3067455589771271), ('Adventure', 0.11784035712480545)]\n",
            "Binary mask for all genres: [1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "example = \"A group of bumbling thieves accidentally steals a gangster’s treasure and must outwit both the police and the mob to survive.\"\n",
        "topk, mask = predict_genres(example, top_k=5)\n",
        "print(\"\\nTop predicted genres & probs:\", topk)\n",
        "print(\"Binary mask for all genres:\", mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeTQpF9EWujr",
        "outputId": "bd5378b6-3316-4a45-df11-eeef7217261a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "\n",
            "Top predicted genres & probs: [('Adventure', 0.8646023273468018), ('Fantasy', 0.8638072609901428), ('Action', 0.8083404302597046), ('Science Fiction', 0.3182853162288666), ('Animation', 0.14917849004268646)]\n",
            "Binary mask for all genres: [1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "example = \"A chosen hero must unite a group of warriors to defeat an evil sorcerer threatening their enchanted world.\"\n",
        "topk, mask = predict_genres(example, top_k=5)\n",
        "print(\"\\nTop predicted genres & probs:\", topk)\n",
        "print(\"Binary mask for all genres:\", mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pbB8FUjW2m7",
        "outputId": "1c809d74-b657-4f63-d12a-5c7946942cd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\n",
            "Top predicted genres & probs: [('Drama', 0.9093378186225891), ('Music', 0.8335316181182861), ('Romance', 0.7966499328613281), ('Comedy', 0.4257875680923462), ('Fantasy', 0.037110645323991776)]\n",
            "Binary mask for all genres: [0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "example = \"A struggling musician falls in love with a dancer, and together they try to achieve their dreams on the stage of a big city.\"\n",
        "topk, mask = predict_genres(example, top_k=5)\n",
        "print(\"\\nTop predicted genres & probs:\", topk)\n",
        "print(\"Binary mask for all genres:\", mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54Cfj7I0W6WM",
        "outputId": "f34d7ade-c94d-4d43-cf4f-592684527c27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\n",
            "Top predicted genres & probs: [('Documentary', 0.8276681900024414), ('Drama', 0.34598904848098755), ('History', 0.13752266764640808), ('Comedy', 0.07212508469820023), ('Foreign', 0.04408174380660057)]\n",
            "Binary mask for all genres: [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "example = \"A detailed look into the life of a famous civil rights leader and the events that shaped their legacy.\"\n",
        "topk, mask = predict_genres(example, top_k=5)\n",
        "print(\"\\nTop predicted genres & probs:\", topk)\n",
        "print(\"Binary mask for all genres:\", mask)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
